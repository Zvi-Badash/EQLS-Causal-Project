{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e5f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "\n",
    "from structure_data import choose_columns, preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9936ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('./')\n",
    "RAW_DATA = ROOT / \"raw_data/csv/eqls_2007and2011.csv\"\n",
    "DICT_PATH = ROOT / \"data/dictionary.json\"\n",
    "GRAPH_PATH = ROOT / \"graphs/full_causal.gpickle\"\n",
    "TREATMENT = \"Y11_Q57\"\n",
    "OUTCOME = \"Y11_MWIndex\"\n",
    "def _prep_ordinals_inplace(df: pd.DataFrame, ord_cols, known_orders=None):\n",
    "    \"\"\"\n",
    "    Map ordinal levels to 0..m-1 and scale to [0,1] so L1 equals Gower per-feature.\n",
    "    known_orders: optional dict {col: [lowest,...,highest]} to control ordering.\n",
    "    \"\"\"\n",
    "    for c in ord_cols:\n",
    "        if known_orders and c in known_orders:\n",
    "            order = {v:i for i, v in enumerate(known_orders[c])}\n",
    "            df[c] = df[c].map(order).astype(float)\n",
    "            m = max(order.values()) if order else 1\n",
    "            df[c] = df[c] / (m if m > 0 else 1.0)\n",
    "        else:\n",
    "            # infer: if numeric-coded, scale minâ€“max; else sort unique labels\n",
    "            if pd.api.types.is_numeric_dtype(df[c]):\n",
    "                lo, hi = df[c].min(), df[c].max()\n",
    "                rng = (hi - lo) if hi > lo else 1.0\n",
    "                df[c] = (df[c] - lo) / rng\n",
    "            else:\n",
    "                levels = sorted(df[c].dropna().unique().tolist())\n",
    "                mapping = {v:i for i, v in enumerate(levels)}\n",
    "                m = max(mapping.values()) if mapping else 1\n",
    "                df[c] = df[c].map(mapping).astype(float) / (m if m > 0 else 1.0)\n",
    "\n",
    "\n",
    "def load_data() -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess the raw EQLS data.\"\"\"\n",
    "    bdvs = ['Y11_EmploymentStatus', 'Y11_HHstructure', 'Y11_HHsize', 'Y11_Agecategory', 'Y11_Q7', 'Y11_Q31', 'Y11_Country', 'Y11_Q32', 'Y11_HH2a', TREATMENT, OUTCOME]\n",
    "    df = choose_columns()\n",
    "    df = preprocess_data(\n",
    "        df,\n",
    "        na_threshold=0.5,\n",
    "        impute_strategy=\"drop\",\n",
    "        treatment_dichotomize_value=\"median\",\n",
    "        treatment_column=TREATMENT,\n",
    "        backdoor_variables=bdvs\n",
    "    )\n",
    "    df.to_csv(\"data/eqls_processed.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "def get_schema() -> dict:\n",
    "    categorical = ['Y11_Q32', 'Y11_Q7']\n",
    "    ordinal = ['Y11_Agecategory','Y11_Country','Y11_EmploymentStatus','Y11_HH2a','Y11_HHsize','Y11_HHstructure','Y11_Q31']\n",
    "    return {\n",
    "        'cat': categorical,\n",
    "        'ord': ordinal\n",
    "    }\n",
    "\n",
    "def load_graph() -> nx.DiGraph:\n",
    "    \"\"\"Load the causal graph describing relationships among variables.\"\"\"\n",
    "    with open(GRAPH_PATH, \"rb\") as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c37b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "METHODS = [\n",
    "    \"backdoor.propensity_score_matching\",\n",
    "    \"backdoor.propensity_score_weighting\",\n",
    "    \"backdoor.propensity_score_stratification\",\n",
    "    \"backdoor.linear_regression\",\n",
    "    \"backdoor.distance_matching\",\n",
    "]\n",
    "DEFAULT_KWARGS = {\n",
    "        \"backdoor.distance_matching\": dict(\n",
    "            target_units=\"ate\",                    # or \"att\"/\"atc\"\n",
    "            method_params={\n",
    "                \"distance_metric\": \"minkowski\",  # L1 with feature weights\n",
    "                \"p\": 1,\n",
    "                \"num_matches_per_unit\": 1,        # change if you want m:1 matching\n",
    "                \"exact_match_cols\": get_schema()['cat'],  # force exact match on pure categoricals\n",
    "            },\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "def estimate_effects(model: CausalModel, df: pd.DataFrame, graph, methods: list = METHODS, kwargs: dict = DEFAULT_KWARGS) -> dict:\n",
    "    _prep_ordinals_inplace(df, get_schema()['ord'])\n",
    "    estimand = model.identify_effect()\n",
    "\n",
    "    results = {}\n",
    "    for m in methods:\n",
    "        try:\n",
    "            est = model.estimate_effect(\n",
    "                estimand, method_name=m, **kwargs.get(m, {})\n",
    "            )\n",
    "            results[m] = float(est.value)\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Estimation with {m} failed: {e}\")\n",
    "            results[m] = float(\"nan\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc273bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Treatment column: Y11_Q57\n",
      "[+] Outcome column: Y11_MWIndex\n",
      "[+] Covariate columns: ['Y11_Country', 'Y11_Q31', 'Y11_Agecategory', 'Y11_HH2a', 'Y11_HHstructure', 'Y11_Q42', 'Y11_Q18', 'Y11_Q44', 'Y11_Q32', 'Y11_HHsize', 'Y11_Accommproblems', 'Y11_Q40a', 'Y11_Q40b', 'Y11_Q40c', 'Y11_Q40d', 'Y11_Q40e', 'Y11_Q40f', 'Y11_Q40g', 'Y11_Q7', 'Y11_EmploymentStatus', 'Y11_RuralUrban', 'Y11_Strainbasedconflict', 'Y11_Q15', 'Y11_Q16', 'Y11_Q12a', 'Y11_Q50d', 'Y11_Q53a']\n",
      "[+] Y11_Country: 0 NA values (0.00%)\n",
      "[+] Y11_Q31: 514 NA values (0.65%)\n",
      "[+] Y11_Agecategory: 0 NA values (0.00%)\n",
      "[+] Y11_HH2a: 0 NA values (0.00%)\n",
      "[+] Y11_HHstructure: 0 NA values (0.00%)\n",
      "[+] Y11_Q42: 141 NA values (0.18%)\n",
      "[+] Y11_Q18: 324 NA values (0.41%)\n",
      "[+] Y11_Q44: 56769 NA values (71.61%)\n",
      "[+] Y11_Q32: 501 NA values (0.63%)\n",
      "[+] Y11_HHsize: 0 NA values (0.00%)\n",
      "[+] Y11_Accommproblems: 748 NA values (0.94%)\n",
      "[+] Y11_Q40a: 1181 NA values (1.49%)\n",
      "[+] Y11_Q40b: 43159 NA values (54.45%)\n",
      "[+] Y11_Q40c: 630 NA values (0.79%)\n",
      "[+] Y11_Q40d: 455 NA values (0.57%)\n",
      "[+] Y11_Q40e: 1097 NA values (1.38%)\n",
      "[+] Y11_Q40f: 469 NA values (0.59%)\n",
      "[+] Y11_Q40g: 1539 NA values (1.94%)\n",
      "[+] Y11_Q7: 30347 NA values (38.28%)\n",
      "[+] Y11_EmploymentStatus: 0 NA values (0.00%)\n",
      "[+] Y11_RuralUrban: 188 NA values (0.24%)\n",
      "[+] Y11_Strainbasedconflict: 42889 NA values (54.10%)\n",
      "[+] Y11_Q15: 44405 NA values (56.02%)\n",
      "[+] Y11_Q16: 60957 NA values (76.90%)\n",
      "[+] Y11_Q12a: 43233 NA values (54.54%)\n",
      "[+] Y11_Q50d: 36198 NA values (45.66%)\n",
      "[+] Y11_Q53a: 1262 NA values (1.59%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/causal/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/causal/lib/python3.11/site-packages/dowhy/causal_estimators/regression_estimator.py:131: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  intercept_parameter = self.model.params[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results (ATE):\n",
      "  backdoor.propensity_score_matching       6.3595\n",
      "  backdoor.propensity_score_weighting      7.0995\n",
      "  backdoor.propensity_score_stratification 6.8997\n",
      "  backdoor.linear_regression               6.8726\n",
      "  backdoor.distance_matching               6.2555\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "df2 = df.copy()\n",
    "graph = load_graph()\n",
    "model = CausalModel(\n",
    "        data=df2,\n",
    "        treatment=TREATMENT,    # must be binary {0,1}\n",
    "        outcome=OUTCOME,\n",
    "        graph=nx.nx_pydot.to_pydot(graph).to_string(),\n",
    "    )\n",
    "results = estimate_effects(model, df2, graph)\n",
    "\n",
    "print(\"Estimation results (ATE):\")\n",
    "for name, val in results.items():\n",
    "    print(f\"  {name:<40} {val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
